#!/usr/bin/env bash
# shellcheck disable=SC1091
source ember_bash_setup &> /dev/null || { printf '%b' '\033[1;31m' >&2; echo "A fatal error was reported on ${BASH_SOURCE[0]} line ${LINENO} in $(pwd): The required dependency ember-shared could not be found (or ember_bash_setup could not be sourced for some other reason)." >&2; printf '%b' '\033[0m' >&2; exit 1; }
#set -x

trap 'die "A fatal error was reported on ${BASH_SOURCE[0]} line ${LINENO} in $(pwd) at $(emdate)."' ERR

# Takes a StageL file as first argument, and prints out equivalent code in the language of the second argument (bash/js).

input="$1"
targetLang="$2"

tokens=()

# First, break up the input into tokens in the tokens array. This doesn't support streaming, so isn't good for long documents, but should suffice for now. The format should be streamable to other formats; this was just easier to implement for now.

pushToken() {
    if [[ -n "${tokens[-1]}" ]]; then
        # There's a token in the last slot in the tokens array, so make a new slot for the next one
        tokens+=("")
        tokens+=("")
    fi
    tokens[-2]="$1"
    tokens[-1]="$2"
    # Make a new slot for whatever happens next
    tokens+=("")
    tokens+=("")
}

insertToken() {
    local insertAfter="$1"
    local newTokenType="$2"
    local newToken="$3"
    local tokensTemp=("${tokens[@]:0:insertAfter}")
    #print_r "${tokensTemp[@]}" >&2
    tokensTemp+=("$newTokenType")
    #print_r "${tokensTemp[@]}" >&2
    tokensTemp+=("$newToken")
    #print_r "${tokensTemp[@]}" >&2
    tokensTemp+=("${tokens[@]:insertAfter}")
    #print_r "${tokensTemp[@]}" >&2
    tokens=("${tokensTemp[@]}")
    #print_r "${tokens[@]}" >&2
}

# We need a dummy token at the beginning so we can insertToken after it (otherwise it would be inserting after something that doesn't exist)
tokens+=("start-document")
tokens+=("")

# Add empty slots to the array for the first token
tokens+=("") # Token type goes in even numbered slots
tokens+=("") # Token content goes in odd numbered slots

parserState="token"
currentIndentLevel="0"
countingIndentSpaces="true"
indentSpacesCounted="0"
lineNumber="1"
columnNumber="1"

while read -r byte; do
    byte=$(( 16#$byte )) # Convert to decimal
    if asciiIsNewline "$byte"; then
        lineNumber=$(( lineNumber + 1 ))
        columnNumber=1
    else
        columnNumber=$(( columnNumber + 1 ))
    fi
    tokenCount="${#tokens[@]}" >&2
    case $parserState in
    token)
        if [[ "$countingIndentSpaces" == "true" ]]; then
            if asciiIsPrintable "$byte" && [[ "$byte" != "32" ]]; then
                countingIndentSpaces="false"
                if [[ "$indentSpacesCounted" -eq $(( ( currentIndentLevel - 1 ) * 4 )) ]]; then
                    pushToken "dedent" ""
                    currentIndentLevel=$(( currentIndentLevel - 1 ))
                elif [[ "$indentSpacesCounted" -eq $(( currentIndentLevel * 4 )) ]]; then
                    true # The expected number of indent spaces was found; do nothing
                elif [[ "$indentSpacesCounted" -eq $(( ( currentIndentLevel + 1 ) * 4 )) ]]; then
                    pushToken "indent" ""
                    currentIndentLevel=$(( currentIndentLevel + 1 ))
                else
                    die "Found $indentSpacesCounted spaces on line $lineNumber, column $columnNumber, but the current indentation level would expect $(( currentIndentLevel * 4 )) spaces."
                fi
            elif [[ "$byte" == "32" ]]; then
                indentSpacesCounted=$(( indentSpacesCounted + 1 ))
            fi
        fi

        if asciiIsNewline "$byte"; then
            countingIndentSpaces="true"
        fi

        if asciiIsLetter "$byte" || [[ "$byte" == 47 ]]; then
            tokens[-1]="${tokens[-1]} $byte"
        elif asciiIsSpace "$byte"; then
            if [[ -n "${tokens[-1]}" ]]; then
                # End of token.
                # There's a token in the last slot in the tokens array, so make a new slot for the next one
                tokens+=("")
                tokens+=("")
            fi
        elif asciiIsNewline "$byte"; then
            # End of token
            if [[ -n "${tokens[-1]}" ]]; then
                tokens+=("")
                tokens+=("")
            fi
        elif [[ "$byte" == 39 ]]; then
            parserState="literal-s"
            tokens[-2]="literal-s"
        elif [[ "$byte" == 35 ]]; then
            parserState="comment"
            tokens[-2]="comment"
        else
            die "Unexpected byte $byte in basic token."
        fi
        ;;
    comment)
        if asciiIsNewline "$byte"; then
            parserState="token"
            tokens+=("")
            tokens+=("")
        elif asciiIsPrintable "$byte"; then
            tokens[-1]="${tokens[-1]} $byte"
        else
            die "Non-printable byte $byte in a comment."
        fi
        ;;
    literal-s)
        if [[ "$byte" == 39 ]]; then
            parserState="token"
            tokens+=("")
            tokens+=("")
        elif asciiIsPrintable "$byte"; then
            tokens[-1]="${tokens[-1]} $byte"
        else
            die "Non-printable byte $byte in a comment."
        fi
        ;;
    *)
        die "Unknown parser state $parserState."
        ;;
    esac
done < <(hexdump -v -e '1/1 "%02X\n"' < "$input")

for (( i=0; i<currentIndentLevel; i++ )); do
    pushToken dedent ""
done

pushToken "end-document" ""

tokenCount="${#tokens[@]}"

# If there's an empty token slot at the end, remove it
if [[ -z "${tokens[-1]}" ]] && [[ -z "${tokens[-2]}" ]]; then
    unset 'tokens[-1]'
    unset 'tokens[-2]'
fi

# Not all the tokens are identified yet. So, now, let's label them all.

inParameterList="false"
for (( i=0; i<tokenCount; i++ )); do
    if (( i % 2 )); then
        if [[ -z "${tokens[$i - 1]}" ]]; then
            # Set the token names in the table for these that aren't yet identified
            case "${tokens[$i]}" in
            " 114 47 115 47 "*)
                tokens[$i - 1]="ident-r-s"
                tokens[$i]="${tokens[$i]# 114 47 115 47}"
                ;;
            " 110 47 "*)
                tokens[$i - 1]="ident-n"
                tokens[$i]="${tokens[$i]# 110 47}"
                ;;
            *)
                tokens[$i - 1]="command"
                ;;
            esac
        fi
    fi
done

tokenCount="${#tokens[@]}"

# Convert command tokens' labels to strings instead of space-separated ASCII
for (( i=0; i<tokenCount; i++ )); do
    if (( i % 2 )); then
        if [[ "${tokens[$i - 1]}" == "command" ]]; then
            echo "${tokens[$i]}" 1>&2
            tokens[$i]="$(asciiDecListToText <<< "${tokens[$i]}")"
        fi
    fi
done

tokenCount="${#tokens[@]}"

echo "Document contains $((tokenCount / 2)) tokens." >&2
for (( i=0; i<tokenCount; i++ )); do
    (( i % 2 )) && echo "Token #$((i / 2 + 1)): ${tokens[$i - 1]}: ${tokens[$i]}" >&2
done

# We now know what each token is, so let's do the code generation.

if [[ "$targetLang" == "parsed" ]]; then
    # Just dump the parse results and exit
    for (( i=0; i<tokenCount; i++ )); do
        (( i % 2 )) && echo "${tokens[$i - 1]} ${tokens[$i]}"
    done
    exit
fi

codegenIndent=0
codegenRoutineName=""
codegenArgList=()

# Define a function for each type of output needed for code generation

codegenPrintIndentationSpaces() {
    for (( j=0; j<codegenIndent; j++ )); do
        print '    '
    done
}

codegenStartDocument() {
    case "$targetLang" in
    "js")
        ;;
    *)
        die "${FUNCNAME[0]} is not implemented in $targetLang."
        ;;
    esac
}

codegenEndDocument() {
    case "$targetLang" in
    "js")
        ;;
    *)
        die "${FUNCNAME[0]} is not implemented in $targetLang."
        ;;
    esac
}

codegenComment() {
    case "$targetLang" in
    "js")
        print "/* $1 */"
        ;;
    *)
        die "${FUNCNAME[0]} is not implemented in $targetLang."
        ;;
    esac
}

codegenCommandInvocation() {
    case "$targetLang" in
    "js")
        print "await $codegenRoutineName("
        print_r "${codegenArgList}"
        print ")"$'\n'
        codegenPrintIndentationSpaces
        ;;
    *)
        die "${FUNCNAME[0]} is not implemented in $targetLang."
        ;;
    esac
    codegenRoutineName=""
    codegenArgList=()
}

codegenRoutineDefinitionStart() {
    case "$targetLang" in
    "js")
        print "async function $codegenRoutineName("
        print_r "${codegenArgList}"
        print ")"$'\n'
        codegenPrintIndentationSpaces
        ;;
    *)
        die "${FUNCNAME[0]} is not implemented in $targetLang."
        ;;
    esac
    codegenRoutineName=""
    codegenArgList=()
}

# Set up the variables we'll need for going through the tokens and generating the code

state="code"
blockStack=("root")

for (( i=0; i<tokenCount; i++ )); do
    if (( i % 2 )); then
        echo "State: $state, token: ${tokens[$i - 1]}: ${tokens[$i]}" >&2
        if [[ "${tokens[$i - 1]}" == "comment" ]]; then
            codegenComment "$(asciiDecListToText "${tokens[$i]}")"
        else
            case "$state" in
            code)
                case "${tokens[$i - 1]}" in
                start-document)
                    codegenStartDocument
                    ;;
                end-document)
                    codegenEndDocument
                    ;;
                indent)
                    codegenIndent=$((codegenIndent + 1))
                    ;;
                dedent)
                    codegenIndent=$((codegenIndent - 1))
                    ;;
                ident-r-*)
                    codegenRoutineName="$(asciiDecListToText "${tokens[$i]}")"
                    state="routine-definition"
                    blockStack+=("${tokens[$i]}")
                    ;;
                command)
                    codegenRoutineName="$(asciiDecListToText "${tokens[$i]}")"
                    state="arglist"
                    ;;
                *)
                    die "A ${tokens[$i - 1]}, ${tokens[$i]}, isn't allowed here, in ${blockStack[-1]}."
                    ;;
                esac
                ;;
            arglist)
                case "${tokens[$i - 1]}" in
                literal-*)
                    # Some type of data, literal.
                    codegenArgList+=("${tokens[$i - 1]}", "${tokens[$i]}")
                    ;;
                ident-*)
                    # Some type of data, reference.
                    codegenArgList+=("${tokens[$i - 1]}", "${tokens[$i]}")
                    print_r "${codegenArgList[@]}" >&2
                    ;;
                *)
                    # The arglist is ended, so do codegen for the command invocation, drop back and continue parsing.
                    codegenCommandInvocation
                    state="code"
                    i=$((i - 2))
                    ;;
                esac
                ;;
            routine-definition)
                # Format: token, [ident...], code body
                # So now we look for as many types as there are. When no more types, it enters the code body of the routine. When there's a dedent, it leaves the code body of the routine.
                case "${tokens[$i - 1]}" in
                ident-*)
                    # Some type of data, reference.
                    codegenArgList+=("${tokens[$i - 1]}", "${tokens[$i]}")
                    ;;
                *)
                    # The routine definition parameter list is ended, so do codegen for the routine declaration (but not the body of it), drop back and continue parsing.
                    codegenRoutineDefinitionStart
                    state="code"
                    i=$((i - 2))
                    ;;
                esac
                ;;
            *)
                die "Unimplemented code generation state $state"
                ;;
            esac
        fi
    fi
done
