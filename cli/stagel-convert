#!/usr/bin/env bash
# shellcheck disable=SC1091
source ember_bash_setup &> /dev/null || { printf '%b' '\033[1;31m' >&2; echo "A fatal error was reported on ${BASH_SOURCE[0]} line ${LINENO} in $(pwd): The required dependency ember-shared could not be found (or ember_bash_setup could not be sourced for some other reason)." >&2; printf '%b' '\033[0m' >&2; exit 1; }
#set -x

trap 'die "A fatal error was reported on ${BASH_SOURCE[0]} line ${LINENO} in $(pwd) at $(emdate)."' ERR

# Takes a StageL file as first argument, and prints out equivalent code in the language of the second argument (bash/js).

input="$1"
targetLang="$2"

tokens=()
# Add empty slots to the array for the first token
tokens+=("") # Token type goes in even numbered slots
tokens+=("") # Token content goes in odd numbered slots
parserState="token"

# First, break up the input into tokens in the tokens array. This doesn't support streaming, so isn't good for long documents, but should suffice for now. The format should be streamable to other formats; this was just easier to implement for now.

while read -r byte; do
    byte=$(( 16#$byte )) # Convert to decimal
    tokenCount="${#tokens[@]}" >&2
    case $parserState in
    token)
        if asciiIsLetter "$byte" || [[ "$byte" == 47 ]]; then
            tokens[-1]="${tokens[-1]} $byte"
        elif asciiIsSpace "$byte"; then
            # End of token
            if [[ -n "${tokens[-1]}" ]]; then
                tokens+=("")
                tokens+=("")
            fi
        elif asciiIsNewline "$byte"; then
            # End of token
            if [[ -n "${tokens[-1]}" ]]; then
                tokens+=("")
                tokens+=("")
            fi
        elif [[ "$byte" == 39 ]]; then
            parserState="literal-str"
            tokens[-2]="literal-str"
        elif [[ "$byte" == 35 ]]; then
            parserState="comment"
            tokens[-2]="comment"
        else
            die "Unexpected byte $byte in basic token."
        fi
        ;;
    comment)
        if asciiIsNewline "$byte"; then
            parserState="token"
            tokens+=("")
            tokens+=("")
        elif asciiIsPrintable "$byte"; then
            tokens[-1]="${tokens[-1]} $byte"
        else
            die "Non-printable byte $byte in a comment."
        fi
        ;;
    literal-str)
        if [[ "$byte" == 39 ]]; then
            parserState="token"
            tokens+=("")
            tokens+=("")
        elif asciiIsPrintable "$byte"; then
            tokens[-1]="${tokens[-1]} $byte"
        else
            die "Non-printable byte $byte in a comment."
        fi
        ;;
    *)
        die "Unknown parser state $parserState."
        ;;
    esac
done < <(hexdump -v -e '1/1 "%02X\n"' < "$input")

# Not all the tokens are identified yet. So, now, let's label them all.

tokenCount="${#tokens[@]}"

for (( i=0; i<tokenCount; i++ )); do
    if (( i % 2 )); then
        if [[ -z "${tokens[$i - 1]}" ]]; then
            case "${tokens[$i]}" in
            " 114 47 115 47 "*)
                tokens[$i - 1]="ident-r-s"
                ;;
            " 110 47 "*)
                tokens[$i - 1]="ident-n"
                ;;
            *)
                tokens[$i - 1]="command"
                ;;
            esac
        fi
    fi
done

# We now know what each token is, so let's do the code generation.

indentationLevel=0
stateStack=("code")
blockStack=("root")

for (( i=0; i<tokenCount; i++ )); do
    if (( i % 2 )); then
        case "${stateStack[-1]}" in
        code)
            case "${tokens[$i - 1]}" in
            ident-r-*)
                echo "Entered routine definition for ${tokens[$i]}."
                indentationLevel=$((indentationLevel + 1))
                stateStack+=("routine-definition")
                blockStack+=("${tokens[$i]}")
                ;;
            ident-n)
                echo "Ident"
                ;;
            *)
                tokens[$i - 1]="command"
                ;;
            esac
            ;;
        routine-definition)
            # Format: token, [type...], code body
            # So now we look for as many types as there are. When no more types, it enters the code body of the routine. When there's a dedent, it leaves the code body of the routine.
            case "${tokens[$i - 1]}" in
            ident-n)
                echo "Routine ${tokens[$i - 2]} has an integer argument"
                ;;
            dedent)
                # This routine dedented without having any body declared.
                warn "The routine ${blockStack[-1]} does not have a body declared."
                indentationLevel=$((indentationLevel - 1))
                unset 'stateStack[-1]'
                unset 'blockStack[-1]'
                ;;
            command)
                stateStack[-1]=("routine-definition-body")
                ;;
            *)
                die "Expected data ident, dedent, or command in routine definition of ${blockStack[-1]}; found ${tokens[$i - 1]}: ${tokens[$i]} instead."
                ;;
            esac
            ;;
        routine-definition-body)
            case "${tokens[$i - 1]}" in
            command)
                # A token in the body of the routine
                echo "Token of routine ${blockStack[-1]} body: ${tokens[$i - 1]}: ${tokens[$i]}"
                ;;
            dedent)
                # Found the end of the routine body.
                indentationLevel=$((indentationLevel - 1))
                unset 'stateStack[-1]'
                unset 'blockStack[-1]'
                ;;
            ident-r-*)
                echo "Entered routine definition for ${tokens[$i]}."
                indentationLevel=$((indentationLevel + 1))
                stateStack+=("routine-definition")
                blockStack+=("${tokens[$i]}")
                ;;
            *)
                die "Expected command, dedent, or routine definition in body of ${blockStack[-1]}; found ${tokens[$i - 1]}: ${tokens[$i]} instead."
                ;;
            esac
            ;;
        *)
            die "Unimplemented code generation state ${stateStack[-1]}"
            ;;
        esac
    fi
done

echo "Document contains $((tokenCount / 2)) tokens." >&2
for (( i=0; i<tokenCount; i++ )); do
    (( i % 2 )) && echo "Token #$i: ${tokens[$i - 1]}: ${tokens[$i]}" >&2
done
